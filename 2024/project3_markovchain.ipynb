{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EXo1DkRozNci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-state Continuous Time Markov Chain\n",
        "\n",
        "Continuous Time Markov Chains are a framework to describe systems where the state space is discrete (i.e. there is only a finite number of possibilities) but the dynamics happen in continuous time and are instrinsically *stochastic*.\n",
        "\n",
        "Let us consider a system which can exist in one of two possible states $1$ or $2$. While in $1$, it can transition with some probability to state $2$, such that the probability for this transition, in time $dt$, is $\\omega^+ dt$.\n",
        "\n",
        "It is called a Markov chain because the probability depends only on the current configuration of the system (i.e. being in the state $1$ or $2$) but does not depend on time, or on the past history (i.e. the system is *memoryless*).\n",
        "\n",
        "The dynamics of the two states are then described by the matrix of rates:\n",
        "\n",
        "$$\n",
        "  L =\n",
        "  \\left[ {\\begin{array}{cc}\n",
        "    \\omega_{1,1} & \\omega_{1,2} \\\\\n",
        "    \\omega_{2,1} & \\omega_{2,2} \\\\\n",
        "  \\end{array} } \\right]\n",
        "$$\n",
        "\n",
        "Such that $\\omega_{i,j}$ is the flux from state $j$ to state $i$\n",
        "In our case of two state, we can conviniently write\n",
        "\n",
        "$$\n",
        "  L =\n",
        "  \\left[ {\\begin{array}{cc}\n",
        "    -\\omega^+ & \\omega^- \\\\\n",
        "    \\omega^+ & -\\omega^- \\\\\n",
        "  \\end{array} } \\right]\n",
        "$$\n",
        "\n",
        "(Notice that the diagonal terms are just the opposite of the other terms, meaning the probability rate of state $1$ to remain in state $1$ is just *minus* its probability rate of going away...)\n",
        "\n",
        "Formally, given the probability vector $\\vec{P(t)} = ( P_1(t), P_2(t) )$, we can write the following partial differential equation for our system:\n",
        "\n",
        "$$\n",
        "\\partial_t \\vec{P(t)} = L \\vec{P(t)}\n",
        "$$\n",
        "\n",
        "This defines the Master Equation, which is the equation that governs the evolution of the probability distribution in time. It has the solution:\n",
        "\n",
        "$$\n",
        "\\vec{P(t)} = e^{Lt}\\vec{P(0)}\n",
        "$$\n",
        "\n",
        "## Equivalence between stochastic realizations and probability evolution.\n",
        "\n",
        "We have shown above that we can describe the evolution of the probabilities using the Master Equation. This is a \"macroscopic\" description.\n",
        "\n",
        "We can also understand the \"microscopic\" description, i.e. single stochastic trajectories of the system, bouncing from one state to another in time. This trajectory will be defined by a sequence of times between jumps $\\{ \\tau_1, \\tau_2, \\dots, \\tau_N\\}$, such that the system which, e.g., starts at $1$ then has a trajectory:\n",
        "\n",
        "$$\n",
        "\\begin{eqnarray}\n",
        "S(t)=1, && 0<t<\\tau_1 \\\\\n",
        "&↓& \\\\\n",
        "S(t)=2,&& \\tau_1<t<\\tau_1+\\tau_2  \\\\\n",
        "&↓&  \\\\\n",
        "S(t) = 1,&& \\tau_1+\\tau_2<t<\\tau_1+\\tau_2+\\tau_3  \\\\\n",
        "&↓&  \\\\\n",
        "&…& \\\\\n",
        "\\end{eqnarray}\n",
        "$$\n",
        "\n",
        "Then, the probability $\\vec{P(t)}$ will describe the probability that *any* single trajectory is in one state or another at time $t$. Empirically, with a number $\\#_{trajs}$ of trajectories, we can approximate the number of trajectories that are in that state at that time.\n",
        "\n",
        "$$\n",
        "P_1^{empirical}(t) = \\frac{1}{\\#_{trajs}}\\sum_{trajs} \\delta(S(t)=1)\n",
        "$$\n",
        "\n",
        "where $\\delta(\\cdot )$ is the Kronecker delta. **Fundamentally, this is the equivalence that you need to numerically demonstrate in the project.**\n",
        "\n",
        "But, how can one simulate single instances of *stochastic* trajectories, given a starting configuration ($\\vec{P(0)}$) and a matrix of transition rates ($L$)?\n",
        "\n",
        "## Gillespie Algorithm.\n",
        "\n",
        "The Gillespie Algorithm is a method to extract the transition times $\\{\\tau_i\\}$ for a trajectory. The central idea is that, since the transition rates are homogeneous (constant) in time, the distribution of transition times is exponential.\n",
        "\n",
        "That is, the rate of leaving the state $1$ ($2$) is $\\omega^+$ ($\\omega^-$). We can then extract the time of residency (i.e., the time *until* the next jump) as:\n",
        "\n",
        "$$\n",
        "\\tau = r \\frac{1}{\\omega^+}\n",
        "$$\n",
        "\n",
        "Where $r$ is an exponentially distributed random variable. Recall that, to transform a uniformly distributed number $u$ into an exponenetially distributed number $r$ one has to perform the following transformation:\n",
        "\n",
        "$$\n",
        "r = \\text{ln} (1/u)\n",
        "$$\n",
        "\n",
        "## Project.\n",
        "\n",
        "- Consider different values of $\\omega^+$ and $\\omega^-$, and calculate analytically (and plot) the result for $\\vec{P(t)}$, using $\\vec{P(0)}=(1,0)$. (Note that it is sufficient to plot $P_1(t)$)\n",
        "- Study the steady state probabilities (what is $\\lim_{t→∞}\\vec{P(t)}$?)\n",
        "- Construct a function that generates a stochastic trajectory of jumping times up to a maximum time $T$\n",
        "- Generates a large number of trajectories, and for a selection of times between $0$ and $T$ compare the empirical probability $P_1^{empirical}(t)$ with the analytical prediction $P_1(t)$\n",
        "\n",
        "- Calculate the instantaneous average current between the two states. You should start away from the stationary states, which should reach zero at long times."
      ],
      "metadata": {
        "id": "wJ6QXchWR0QJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "### References\n"
      ],
      "metadata": {
        "id": "ez-mZ2Fl7lR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "H_dypizAR0Fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CTctL7-Ry--"
      },
      "outputs": [],
      "source": []
    }
  ]
}